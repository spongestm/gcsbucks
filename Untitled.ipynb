{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acf26f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3054032",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d700d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-storage in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-cloud-storage) (2.37.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-cloud-storage) (2.24.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-cloud-storage) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-cloud-storage) (2.7.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-cloud-storage) (2.31.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-cloud-storage) (1.6.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.66.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (5.29.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.25.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (4.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2023.7.22)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-cloud-storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "573b7be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the path to your service account key file\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = r\"C:\\Users\\Sponges-TM\\Untitled Folder\\service_account_key.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1074ced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging  # For logging warnings and messages\n",
    "import os  # To interact with environment variables\n",
    "import traceback  # To capture and display error tracebacks\n",
    "import re  # For working with regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20f3669b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-bigquery in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (3.27.0)\n",
      "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=2.11.1 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-cloud-bigquery) (2.24.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-cloud-bigquery) (2.37.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=2.4.1 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-cloud-bigquery) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-cloud-bigquery) (2.7.2)\n",
      "Requirement already satisfied: packaging>=20.0.0 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-cloud-bigquery) (23.1)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.3 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-cloud-bigquery) (2.8.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-cloud-bigquery) (2.31.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=2.11.1->google-cloud-bigquery) (1.66.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=2.11.1->google-cloud-bigquery) (5.29.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=2.11.1->google-cloud-bigquery) (1.25.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=2.11.1->google-cloud-bigquery) (1.68.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=2.11.1->google-cloud-bigquery) (1.68.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (4.9)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from google-resumable-media<3.0dev,>=2.0.0->google-cloud-bigquery) (1.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from python-dateutil<3.0dev,>=2.7.3->google-cloud-bigquery) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2023.7.22)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\sponges-tm\\anaconda3\\anaconda03\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-bigquery\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca73d09",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Import Google Cloud libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97f3034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery  # For interacting with Google BigQuery\n",
    "from google.cloud import storage  # For accessing Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7521781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml  # For reading YAML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3dc64faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load schema configuration from a YAML file (e.g., schemas.yaml)\n",
    "with open(r\"C:\\Users\\Sponges-TM\\Untitled Folder\\schemas.yaml\") as schema_file:\n",
    "     config = yaml.load(schema_file, Loader=yaml.Loader)  # Load YAML content into a Python object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4ed19c",
   "metadata": {},
   "source": [
    "# Global variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31b82a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = os.getenv('cloudquicklab')  # GCP Project ID (fetched from environment variable)\n",
    "BQ_DATASET = 'staging'  # Name of the BigQuery dataset to store data\n",
    "CS = storage.Client()  # Initialize Google Cloud Storage client\n",
    "BQ = bigquery.Client()  # Initialize BigQuery client\n",
    "job_config = bigquery.LoadJobConfig()  # Initialize BigQuery job configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0ef6c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def streaming(data):\n",
    "    \"\"\"\n",
    "    Main function to process incoming data, check table existence, and load data into BigQuery.\n",
    "    Args:\n",
    "        data (dict): Dictionary containing information about the uploaded file.\n",
    "                     Keys: 'bucket', 'name', 'timeCreated'\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c17a0e5",
   "metadata": {},
   "source": [
    "  # Extract bucket name, filename, and timeCreated from input data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dbdd3b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample input data simulating a GCS file event\n",
    "data = {\n",
    "    \"bucket\": \"gcs-bucket-name\",  # Replace with your GCS bucket name\n",
    "    \"name\": \"file.json\",  # Replace with the name of your file\n",
    "    \"timeCreated\": \"2024-06-14T00:00:00Z\"  # Replace with the actual creation timestamp\n",
    "}\n",
    "\n",
    "# Call the main streaming function with the input data\n",
    "streaming(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a1393b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket name: gcs-bucket-name\n",
      "File name: file.json\n",
      "Time Created: 2024-06-14T00:00:00Z\n"
     ]
    }
   ],
   "source": [
    " bucketname = data['bucket'] \n",
    "print(\"Bucket name:\", bucketname)\n",
    "filename = data['name']   \n",
    "print(\"File name:\", filename)  \n",
    "timeCreated = data['timeCreated']\n",
    "print(\"Time Created:\", timeCreated) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a8a0839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Code to attempt\n",
    "    for table in config:\n",
    "        tableName = table.get(\"name\")  # Indented code block\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fcc7a2",
   "metadata": {},
   "source": [
    "##  # Check if the filename matches the table name using regular expressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0eed2425",
   "metadata": {},
   "outputs": [],
   "source": [
    "            if re.search(tableName.replace(\"_\", \"-\"), filename) or re.search(tableName, filename):\n",
    "                tableSchema = table.get(\"schema\")  # Get the table schema from YAML\n",
    "                _check_if_table_exists(tableName, tableSchema)  # Ensure the table exists in BigQuery\n",
    "                tableFormat = table.get(\"format\")  # Get the expected file format (e.g., JSON)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885266c4",
   "metadata": {},
   "source": [
    " # If the file format matches 'NEWLINE_DELIMITED_JSON', load it into BigQuery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7899d4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Loop through the configuration list to process each table\n",
    "    for table in config:\n",
    "        tableName = table.get('name')  # Get the table name\n",
    "        # Check if the table name matches any part of the filename (allowing underscores or hyphens)\n",
    "        if re.search(tableName.replace('_', '-'), filename) or re.search(tableName, filename):\n",
    "            tableSchema = table.get('schema')  # Get the schema for the table\n",
    "            _check_if_table_exists(tableName, tableSchema)  # Check if the table exists in the schema\n",
    "            tableFormat = table.get('format')  # Get the table format\n",
    "\n",
    "            # If the table format is 'NEWLINE_DELIMITED_JSON', process the table accordingly\n",
    "            if tableFormat == 'NEWLINE_DELIMITED_JSON':\n",
    "                _load_table_from_uri(data['bucket'], data['name'], tableSchema, tableName)  # Load the table data from the URI\n",
    "\n",
    "# Catch and handle any exceptions that occur during the file processing\n",
    "except Exception:\n",
    "    # Print the error message and include the exception details\n",
    "    print('Error streaming file. Cause: %s' % (traceback.format_exc()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c8b6e12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_if_table_exists(tableName, tableSchema):\n",
    "    \"\"\"\n",
    "    Checks if the specified table exists in BigQuery. If not, creates the table.\n",
    "    Args:\n",
    "        tableName (str): Name of the table to check.\n",
    "        tableSchema (dict): Table schema definition from YAML file.\n",
    "    \"\"\"\n",
    "    # Construct a BigQuery table ID\n",
    "    table_id = BQ.dataset(BQ_DATASET).table(tableName)\n",
    "\n",
    "    try:\n",
    "        # Attempt to fetch the table to verify its existence\n",
    "        BQ.get_table(table_id)\n",
    "    except Exception:\n",
    "        # If the table doesn't exist, create it\n",
    "        logging.warning(\"Creating table: %s\" % (tableName))\n",
    "        schema = create_schema_from_yaml(tableSchema)  # Convert YAML schema to BigQuery schema\n",
    "        table = bigquery.Table(table_id, schema=schema)  # Create a BigQuery table object\n",
    "        table = BQ.create_table(table)  # Create the table in BigQuery\n",
    "        print(\"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c7b59fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_table_from_uri(bucket_name, file_name, tableSchema, tableName):\n",
    "    \"\"\"\n",
    "    Loads a file from Google Cloud Storage into a BigQuery table.\n",
    "    Args:\n",
    "        bucket_name (str): Name of the GCS bucket.\n",
    "        file_name (str): Name of the file in the bucket.\n",
    "        tableSchema (dict): Table schema definition from YAML file.\n",
    "        tableName (str): Name of the BigQuery table to load data into.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdbf82a",
   "metadata": {},
   "source": [
    "# Construct the GCS file URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9886c7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    " uri = \"gs://%s/%s\" % (bucketname, filename)\n",
    "table_id = BQ.dataset(BQ_DATASET).table(tableName)  # Construct the BigQuery table ID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16f8ae2",
   "metadata": {},
   "source": [
    " ### Create BigQuery schema from YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5b93a681",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tableSchema' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m         schema\u001b[38;5;241m.\u001b[39mappend(schemaField)\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m schema\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28mprint\u001b[39m(tableSchema)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tableSchema' is not defined"
     ]
    }
   ],
   "source": [
    "def create_schema_from_yaml(tableSchema):\n",
    "    \"\"\"\n",
    "    Converts a table schema definition from YAML format to a BigQuery-compatible schema.\n",
    "    Args:\n",
    "        table_schema (list): List of column definitions in YAML format. Each column is defined as:\n",
    "                             - name: The field name (str).\n",
    "                             - type: The field type (e.g., STRING, INTEGER, RECORD).\n",
    "                             - mode: The mode of the field (e.g., NULLABLE, REQUIRED, REPEATED).\n",
    "                             - fields (optional): For RECORD type, a nested list of field definitions.\n",
    "    Returns:\n",
    "        list: A list of BigQuery SchemaField objects.\n",
    "    \"\"\"\n",
    "    schema = []\n",
    "    # Iterate through each column definition in the YAML schema\n",
    "    for column in tableSchema:\n",
    "        # Create a SchemaField object for each column\n",
    "        schemaField = bigquery.SchemaField(\n",
    "            name=column[\"name\"],  # Field name\n",
    "            field_type=column[\"type\"],  # Field type (e.g., STRING, INTEGER)\n",
    "            mode=column.get(\"mode\", \"NULLABLE\")  # Field mode, defaulting to NULLABLE if not specified\n",
    "        )\n",
    "        # If the column is a RECORD type, process its nested fields recursively\n",
    "        if column[\"type\"] == \"RECORD\" and \"fields\" in column:\n",
    "            schemaField._fields = create_schema_from_yaml(column[\"fields\"])\n",
    "        # Add the SchemaField to the schema list\n",
    "        schema.append(schemaField)\n",
    "    return schema\n",
    "print(tableSchema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0f481743",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tableSchema' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m schema \u001b[38;5;241m=\u001b[39m create_schema_from_yaml(tableSchema)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSchema being used:\u001b[39m\u001b[38;5;124m\"\u001b[39m, schema)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tableSchema' is not defined"
     ]
    }
   ],
   "source": [
    "schema = create_schema_from_yaml(tableSchema)\n",
    "print(\"Schema being used:\", schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dffd78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
